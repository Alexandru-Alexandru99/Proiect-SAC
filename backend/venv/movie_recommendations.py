# -*- coding: utf-8 -*-
"""movie-recommendations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rTvj3JRFK3479o0QK5LZw8cqpFwnYk5Z
"""

import pandas as pd 
import numpy as np 
from ast import literal_eval
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity


def get_director(x):
    for i in x:
        if i['job'] == 'Director':
            return i['name']
    return np.nan

# Returns the list top 3 elements
def get_list(x):
    if isinstance(x, list):
        names = [i['name'] for i in x]
        if len(names) > 3:
            names = names[:3]
        return names
    return []

# Convert all strings to lower case and strip names of spaces
def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        #Check if director exists. If not, return empty string
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

def create_cosinus_matrix():
    df2=pd.read_csv('./dataset/merged_movies.csv')
    # Parse the string features into their corresponding python objects
    features = ['cast', 'crew', 'keywords', 'genres']
    for feature in features:
        df2[feature] = df2[feature].apply(literal_eval)

    # Redefine relevant features into a suitable form
    df2['director'] = df2['crew'].apply(get_director)

    features = ['cast', 'keywords', 'genres']
    for feature in features:
        df2[feature] = df2[feature].apply(get_list)

    # Apply clean_data function to your features.
    features = ['cast', 'keywords', 'director', 'genres']

    for feature in features:
        df2[feature] = df2[feature].apply(clean_data)

    # Create single string with all features (separated by space)
    def create_soup(x):
        return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
    df2['soup'] = df2.apply(create_soup, axis=1)

    # Count the the number of word appearences
    count = CountVectorizer(stop_words='english')
    count_matrix = count.fit_transform(df2['soup'])

    cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

    # Reset index of our main DataFrame and construct reverse mapping as before
    df2 = df2.reset_index()

    return cosine_sim2

def get_recommendations(preffered_movies_indices, cosine_sim):
    aggregated_scores = [(0, 0)] * len(cosine_sim)
    for idx in preffered_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]

    aggregated_scores = sorted(aggregated_scores, key=lambda x: x[1], reverse=True)
    aggregated_scores = aggregated_scores[0:30]
    final_result = [(id, score) for (id, score) in aggregated_scores if id not in preffered_movies_indices]
    movie_indices = [i[0] for i in final_result]
    # df2['title'].iloc[movie_indices].values.tolist()
    return movie_indices

def get_recommendations_using_3_factors(preffered_movies_indices, viewed_movies_indices, searched_movies_indices, cosine_sim):
    aggregated_scores = [(0, 0)] * len(cosine_sim)
    for idx in preffered_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 3.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(preffered_movies_indices)) for (id, score) in aggregated_scores]
    
    for idx in viewed_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 2.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(viewed_movies_indices)) for (id, score) in aggregated_scores]
    
    for idx in searched_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 1.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(searched_movies_indices)) for (id, score) in aggregated_scores]

    aggregated_scores = sorted(aggregated_scores, key=lambda x: x[1], reverse=True)
    aggregated_scores = aggregated_scores[0:30]
    final_result = [(id, score) for (id, score) in aggregated_scores if id not in preffered_movies_indices + viewed_movies_indices]
    movie_indices = [i[0] for i in final_result]
    # df2['title'].iloc[movie_indices].values.tolist()
    return movie_indices

def get_intralist_similarity(preffered_movies_indices, viewed_movies_indices, searched_movies_indices, cosine_sim):
    aggregated_scores = [(0, 0)] * len(cosine_sim)
    for idx in preffered_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 3.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(preffered_movies_indices)) for (id, score) in aggregated_scores]
    
    for idx in viewed_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 2.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(viewed_movies_indices)) for (id, score) in aggregated_scores]
    
    for idx in searched_movies_indices:
      # Get the pairwsie similarity with that specific movie
      sim_scores = list(enumerate(cosine_sim[idx]))
      aggregated_scores = [(id, score1 + 1.0 * score2) for ((_, score1), (id, score2)) in zip(aggregated_scores, sim_scores)]
    aggregated_scores = [(id, score / len(searched_movies_indices)) for (id, score) in aggregated_scores]

    aggregated_scores = sorted(aggregated_scores, key=lambda x: x[1], reverse=True)
    aggregated_scores = aggregated_scores[0:30]
    final_result = [(id, score) for (id, score) in aggregated_scores if id not in preffered_movies_indices + viewed_movies_indices]
    movie_indices = [i[0] for i in final_result]
    # df2['title'].iloc[movie_indices].values.tolist()

    number_sim = 0
    sum_sim = 0
    for m1 in movie_indices:
      for m2 in movie_indices:
        if m1 != m2:
          number_sim += 1
          sum_sim += list(enumerate(cosine_sim[m1]))[m2][1]
    intralist_similarity = 1.0 * sum_sim / number_sim


    return intralist_similarity

# print(get_recommendations([867, 2731, 2], cosine_sim2))